{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ef0c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce999833",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"pcsk_4H9c5h_KWCvM9XyAQBM62c4S2wc7KJpHctFJCYSkVJZP5N72pTr4xz1AP2RpecmToC9Toz\"\n",
    "\n",
    "PINECONE_API_ENV = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d65070c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81c158ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8bafca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b87308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting text:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 879/1207 [07:59<01:16,  4.26it/s]  "
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF using pdfplumber, skipping pages 200 to 300 (1-based index), and show progress.\"\"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        total_pages = len(pdf.pages)\n",
    "        for i in tqdm(range(total_pages), desc=\"Extracting text\"):\n",
    "            if 199 <= i <= 299:  # skip pages from 200 - 300 (error in pages)\n",
    "                continue\n",
    "            page_text = pdf.pages[i].extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Extract text\n",
    "extracted_data = load_pdf(r\"C:\\Users\\mohda\\OneDrive\\Desktop\\generative ai project3\\Data\\India Travel Guide.pdf\")\n",
    "print(extracted_data[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a0e03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 9157 text chunks from PDF.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "text_chunks = text_splitter.split_text(extracted_data)\n",
    "\n",
    "print(f\"Extracted {len(text_chunks)} text chunks from PDF.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9797c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from sentence-transformers) (4.48.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "! pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e1216",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c5b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6f2626",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7206c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0293962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cd20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394bea54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Embedding Vector: [0.05694784224033356, -0.03384576365351677, -0.03826654702425003, 0.029937393963336945, -0.0020012466702610254, -0.01088137086480856, 0.05203469470143318, 0.004358153790235519, -0.03935890272259712, -0.014833830296993256]\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "text = \"what are top ten places to visit in inida?\"\n",
    "query_embedding = embedding_model.embed_query(text)\n",
    "\n",
    "print(\"Generated Embedding Vector:\", query_embedding[:10])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c1fa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516a346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843c2f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ba16e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pinecone in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (6.0.2)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from Pinecone) (2024.12.14)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from Pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from Pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from Pinecone) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from Pinecone) (2.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from python-dateutil>=2.5.3->Pinecone) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c86ce8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ No 'pinecone.py' file found in your current directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "target_file = os.path.join(cwd, \"pinecone.py\")\n",
    "\n",
    "if os.path.isfile(target_file):\n",
    "    new_name = os.path.join(cwd, \"pinecone_old.py\")\n",
    "    os.rename(target_file, new_name)\n",
    "    print(f\"‚úÖ Renamed 'pinecone.py' to 'pinecone_old.py'\")\n",
    "else:\n",
    "    print(\"‚úÖ No 'pinecone.py' file found in your current directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48f35f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pinecone 6.0.2\n",
      "Uninstalling pinecone-6.0.2:\n",
      "  Successfully uninstalled pinecone-6.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping pinecone-client as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall pinecone -y\n",
    "! pip uninstall pinecone-client -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef8898b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è© No __pycache__ found\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "sys.modules.pop(\"pinecone\", None)\n",
    "\n",
    "if os.path.exists(\"__pycache__\"):\n",
    "    shutil.rmtree(\"__pycache__\")\n",
    "    print(\"‚úÖ Removed __pycache__\")\n",
    "else:\n",
    "    print(\"‚è© No __pycache__ found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dc3291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pinecone\n",
      "  Using cached pinecone-6.0.2-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pinecone) (2024.12.14)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pinecone) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pinecone) (2.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mohda\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
      "Using cached pinecone-6.0.2-py3-none-any.whl (421 kB)\n",
      "Installing collected packages: pinecone\n",
      "Successfully installed pinecone-6.0.2\n"
     ]
    }
   ],
   "source": [
    "! pip install pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63176a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported pinecone from: c:\\Users\\mohda\\anaconda3\\envs\\testingopenai\\Lib\\site-packages\\pinecone\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "print(\"Imported pinecone from:\", pinecone.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfce9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to index: genai\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone \n",
    "\n",
    "pc = Pinecone(api_key=\"pcsk_4H9c5h_KWCvM9XyAQBM62c4S2wc7KJpHctFJCYSkVJZP5N72pTr4xz1AP2RpecmToC9Toz\")  # Replace with your API key\n",
    "\n",
    "index_name = \"genai\"\n",
    "region = \"us-east-1\"  \n",
    "\n",
    "index = pc.Index(index_name)\n",
    "print(f\"Connected to index: {index_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d022fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF for PDF text extraction\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone as PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\") + \"\\n\"\n",
    "    return text\n",
    "\n",
    "pdf_path = r\"C:\\Users\\mohda\\OneDrive\\Desktop\\generative ai project3\\Data\\India Travel Guide.pdf\"  # Replace with the actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea7e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = extract_text_from_pdf(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a064d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RecursiveCharacterTextSplitter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m \u001b[43mRecursiveCharacterTextSplitter\u001b[49m(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m      2\u001b[0m text_chunks \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_text(extracted_text)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Extracted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m text chunks from PDF.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RecursiveCharacterTextSplitter' is not defined"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "text_chunks = text_splitter.split_text(extracted_text)\n",
    "print(f\"‚úÖ Extracted {len(text_chunks)} text chunks from PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8c84ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to index: genai\n",
      "Upserted 3 vectors so far.\n",
      "‚úÖ PDF text chunks successfully converted to vectors and stored in Pinecone!\n"
     ]
    }
   ],
   "source": [
    "# üîπ Step 3: Initialize Pinecone Client\n",
    "pc = Pinecone(api_key=\"pcsk_4H9c5h_KWCvM9XyAQBM62c4S2wc7KJpHctFJCYSkVJZP5N72pTr4xz1AP2RpecmToC9Toz\")  # Replace with your actual API Key\n",
    "\n",
    "# Define Pinecone index details\n",
    "index_name = \"genai\"\n",
    "expected_dim = 384  # Ensure embeddings match this dimension\n",
    "\n",
    "\n",
    "\n",
    "# Connect to the existing index\n",
    "index = pc.Index(index_name)\n",
    "print(f\"Connected to index: {index_name}\")\n",
    "\n",
    "# üîπ Step 4: Convert Text Chunks into Vector Embeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings = embedding_model.embed_documents(text_chunks)\n",
    "\n",
    "# üîπ Step 5: Format Data for Pinecone Upsert\n",
    "vectors = [\n",
    "    {\"id\": f\"doc_{i}\", \"values\": embeddings[i], \"metadata\": {\"text\": text_chunks[i]}}\n",
    "    for i in range(len(text_chunks))\n",
    "]\n",
    "\n",
    "# üîπ Step 6: Store Vectors in Pinecone\n",
    "batch_size = 100  # To prevent exceeding Pinecone's request limits\n",
    "for i in range(0, len(vectors), batch_size):\n",
    "    index.upsert(vectors=vectors[i : i + batch_size])\n",
    "    print(f\"Upserted {i + len(vectors[i : i + batch_size])} vectors so far.\")\n",
    "\n",
    "print(\"‚úÖ PDF text chunks successfully converted to vectors and stored in Pinecone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1d6ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"genai\",\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"genai-kvk4kva.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 384,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if index_name in pc.list_indexes().names():\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff6cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone as PineconeVectorStore\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ea6862",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_info = pc.describe_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ec63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_url = \"https://genai-kvk4kva.svc.aped-4627-b74a.pinecone.io\"  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bdce0c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0231bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to Pinecone index: genai\n"
     ]
    }
   ],
   "source": [
    "index = pc.Index(index_name, host=host_url)\n",
    "\n",
    "print(f\"‚úÖ Connected to Pinecone index: {index_name}\")\n",
    "\n",
    "index_name = \"genai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c78fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe6267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_response(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  \n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf7d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Query Results:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"where is hyderabad?\"\n",
    "query_embedding = embedding_model.embed_query(query)\n",
    "\n",
    "query_result = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=5,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(\"\\nüîç Query Results:\")\n",
    "for match in query_result[\"matches\"]:\n",
    "    score = match[\"score\"]\n",
    "    text = match[\"metadata\"].get(\"text\", \"‚ö† No matching text found\")\n",
    "    print(f\"üîπ Confidence Score: {score:.4f}\")\n",
    "    print(f\"üìÑ Retrieved Text: {text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc22a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "print(index.describe_index_stats())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testingopenai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
